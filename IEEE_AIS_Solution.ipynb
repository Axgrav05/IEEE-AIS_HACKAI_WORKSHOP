{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Welcome to IEEE x AIS Workshop!**\n",
        "\n",
        "In this notebook, we will:\n",
        "1. Create an artificial dataset\n",
        "2. Import and explore the data\n",
        "3. Visualize relationships using graphs\n",
        "4. Preprocess the data\n",
        "5. Train a Machine Learning Model\n",
        "6. Evaluate the model's performance\n"
      ],
      "metadata": {
        "id": "uRDxmzGbz5nX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CELL 1: INSTALL & IMPORT REQUIRED LIBRARIES ---\n",
        "!pip install seaborn scikit-learn"
      ],
      "metadata": {
        "id": "W9soMYW9z6xH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import mean_squared_error, r2_score"
      ],
      "metadata": {
        "id": "FxPyASoKz-fo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 1: Creating an Artificial Dataset**\n",
        "To demonstrate data science concepts, we generate a synthetic dataset mimicking electronic component failure."
      ],
      "metadata": {
        "id": "fHepgRmzz_5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CELL 2: GENERATE ARTIFICIAL DATASET ---\n",
        "n_samples = 1000\n",
        "np.random.seed(42)\n",
        "\n",
        "data = pd.DataFrame({\n",
        "    \"Voltage_Tolerance\": np.random.normal(5, 0.5, n_samples),\n",
        "    \"Temperature_Cycle\": np.random.randint(0, 500, n_samples),\n",
        "    \"Humidity_Level\": np.random.uniform(10, 90, n_samples),\n",
        "    \"Manufacturing_Defect\": np.random.choice([0, 1], n_samples, p=[0.99, 0.1]),\n",
        "    \"Vibration_Exposure\": np.random.uniform(0, 5, n_samples),\n",
        "    \"Component_Age\": np.random.randint(1, 10, n_samples),\n",
        "    \"Failure_Label\": np.random.choice([0, 1], n_samples, p=[0.8, 0.2])\n",
        "})\n",
        "\n",
        "print(\"Sample of Dataset:\")\n",
        "print(data.head())"
      ],
      "metadata": {
        "id": "QKU36K820B_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 2: Exploring the Dataset**\n",
        "Before training a model, we need to understand the dataset."
      ],
      "metadata": {
        "id": "B73deulr0D3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CELL 3: DATA EXPLORATION ---\n",
        "print(\"Dataset Overview:\")\n",
        "print(data.describe())\n",
        "\n",
        "print(\"\\nClass Distribution:\")\n",
        "print(data[\"Failure_Label\"].value_counts())"
      ],
      "metadata": {
        "id": "dlOC0RS90FQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 3: Visualizing the Data**\n",
        "We'll use seaborn and matplotlib to analyze feature relationships.\n"
      ],
      "metadata": {
        "id": "FlGn3Nt30HIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CELL 4: DATA VISUALIZATION ---\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.heatmap(data.corr(), annot=True, cmap=\"coolwarm\", linewidths=0.5)\n",
        "plt.title(\"Feature Correlation Heatmap\")\n",
        "plt.show()\n",
        "\n",
        "# TODO: Replace ___ with the correct argument for pairplot\n",
        "sns.pairplot(data, hue=\"Failure_Label\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hw9oINdp0JZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 4: Preprocessing Data**\n",
        "We need to split the data into training and test sets and normalize it."
      ],
      "metadata": {
        "id": "_4W54V3k0UiE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CELL 5: PREPROCESSING DATA ---\n",
        "X = data.drop(columns=[\"Failure_Label\"])\n",
        "y = data[\"Failure_Label\"]\n",
        "\n",
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "rXxr4qGi0VUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 5: Training a Machine Learning Model**\n",
        "We'll use a Random Forest Classifier to predict failures."
      ],
      "metadata": {
        "id": "TZLAeyTg0apR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CELL 6: MODEL TRAINING ---\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train_scaled, y_train)"
      ],
      "metadata": {
        "id": "Iu6IzJDP0bEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 6: Evaluating the Model**\n",
        "Checking accuracy and performance of the model.\n"
      ],
      "metadata": {
        "id": "1c9pn83s0fDu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CELL 7: MODEL EVALUATION ---\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "print(\"Model Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "UEoqZzx50fTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 7: Visualizing Performance**\n",
        "Confusion matrix visualization to interpret model results."
      ],
      "metadata": {
        "id": "HVkxsgb30kLq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CELL 8: CONFUSION MATRIX ---\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Reliable\", \"Failure\"], yticklabels=[\"Reliable\", \"Failure\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "eMk09DI-0kc3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}